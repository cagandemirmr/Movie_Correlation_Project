# -*- coding: utf-8 -*-
"""Movie_portfolio_project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oFipMfhhqeJJPIOOHPbPtl02cFwaXHYN

# Correlation of Movies

Importing Necessary Librares
"""

# Commented out IPython magic to ensure Python compatibility.
#Import Libraries
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.mlab as mlab
import matplotlib
import missingno as msno
plt.style.use('ggplot')
from matplotlib.pyplot import figure
'''pd.set_option ('display.max_columns', None)
pd.set_option('display.width', 1000)'''
pd.set_option("display.max_rows",None)

# %matplotlib inline
matplotlib.rcParams['figure.figsize'] = (12,8)

pd.options.mode.chained_assignment = None

#Read csv file
df=pd.read_csv("jetbrains://pycharm/navigate/reference?project=pythonProject8&path=movies.csv")


def nunique_val(dataframe,col,head=5):
  print(col,dataframe[col].nunique())
  print(dataframe[col].head(),"\n\n\n")

for col in df.columns:
  nunique_val(dataframe=df,col=col)

# Scope of Project
df.head()

#Problems i observe is that in released column format is wrong.Personally, i wanted to seperate country value from released column.

"""# Null Value Analysis"""

df.isnull().sum()

#Visualization of Null Values
msno.matrix(df)

#Null Correlation
msno.heatmap(df)

#Relationship Between "genre","budget" and "rating" analyzed.
df.groupby(["genre","budget","rating"]).agg({"budget":"mean"})

"""# Categoric and Numeric Variable Analysis"""

#First upload my functions
def grab_col_names(dataframe,cat_th=10,car_th=30):
  """
  veri setinde numerik,kategorik ve kategoric ama kardinal değişkenlerin isimlerini verir.
  Parameters
  ----------
  dataframe:dataframe
    Değişken isimleri alınmak istenen Dataframe dir.

  cat_th:int,float
    numerik fakat kategorik olan değişkenler için eşik değeri

  car_th:int,float
    Kategorik fakat kardinal değişkenler için sınıf değeri

  Returns
  ----------
  cat_cols:Liste
    Kategorik değişken Listesi

  num_cols:Liste
    Numerik değişken listesi

  cat_but_car:Liste
    Kardinal değişken listesi

  Notes
  ----------
  cat_cols +num_cols +cat_cut_car = toplam değişken sayısı
  num_but_cat cat_cols un içerisinde.
  Return olan 3 liste toplan toplan degisken sayisina esittir: cat_cols + num_cols + cat_but_car

  """
  cat_cols=[col for col in df.columns if str(df[col].dtypes) in ["category","object","bool"]]
  num_but_cat =[col for col in df.columns if (df[col].nunique() < cat_th) and (df[col].dtypes in ["int","float"])]
  cat_but_car=[col for col in df.columns if df[col].nunique()>car_th and str(df[col].dtypes) in ["category","object"]]
  cat_cols = cat_cols+num_but_cat
  cat_cols = [col for col in cat_cols if col not in cat_but_car]

  num_cols=[col for col in df.columns if str(df[col].dtype) in ["float64","int64"]]
  num_cols=[col for col in num_cols if col not in cat_cols]
  print(f"Observations: {dataframe. shape [0]}")
  print(f"Variables: {dataframe.shape[1]}")
  print(f' cat_cols: {len(cat_cols)} ')
  print(f' num_cols: {len(num_cols)}')
  print(f' cat_but_car: {len(cat_but_car)}')
  print(f' num_but_cat: {len(num_but_cat)}')
  return cat_cols,num_cols,cat_but_car

  cat_cols,num_cols,cat_but_car=grab_col_names(df,10,20)

def cat_summary(dataframe,col_name,plot=False):
  """Kategorik değişkenlerin miktarı ve yüzdesi ve grafiğinin görülmesi için bu yöntem tercih  edilir.
Parameters
--------
Dataframe:Pandas dataframe type
col_name:column name from relevant dataframe
plot:count plot from of column.Deffault value False.
--------
Return
print>>>Ratio of relevant category
if plot==True:
print>>countplot
-------
  """
  print(pd.DataFrame({col_name:dataframe[col_name].value_counts(),
                      "Ratio":100*dataframe[col_name].value_counts()/len(dataframe)}))
  print("*******************************")
  if plot:
    sns.countplot(x=dataframe[col_name],data=dataframe)
    plt.show(block=True)

def num_summary(dataframe,numerical_col,plot=False):
  """Numerik değişkenlerin çeyreklikleri, histogramı ve boxplotunun görülmesi için ideal bir araçtır.
  """
  print("********")
  quantiles = [0.05,0.10,0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90,0.99]
  print(dataframe[numerical_col].describe(quantiles).T)
  if plot:
    sns.histplot(data=df,x=df[col])
    plt.show()
    sns.boxplot(data=df,x=df[col])
    plt.show()

#Definin variables whether numeric,categoric or cardinal
cat_cols,num_cols,cat_but_car=grab_col_names(df,42,2386)

#Checking Variables
df[cat_cols].head()

df[num_cols].head()

df[cat_but_car].head()

#Analyzing categorical Values
for col in cat_cols:
  cat_summary(df,col_name=col,plot=True)

#Analyzing Numeric Values
for col in num_cols:
  num_summary(df,col,plot=True)

#Detecting Null Values Version 1
df.isnull().sum()

#Detecting Null Values Version 2
for col in df.columns:
  pct_missing=np.mean(df[col].isnull())
  print('{} - {}%'.format(col,pct_missing))

#Data types for our columns
df.dtypes

df.head()

#Changing Budged and gross values into integer

df['budget'] = pd.to_numeric(df['budget'], errors='coerce').fillna(0).astype(int)

df['gross'] = pd.to_numeric(df['gross'], errors='coerce').fillna(0).astype(int)

#To compare year and released coloumns in terms of date
date=[]
for col in df["released"].astype(str):
  new_col=col.strip(")").split("(")
  if len(new_col) ==2:
    date.append(new_col[0])
  else:
    date.append(new_col)

#df["Date"]=pd.Series(data=date)

year_source=[]
for i in range(len(df["year"])):
  a="".join(df["year"][i].astype(str))
  year_source.append(a)

year_corr=[]
for i in range(len(df["year"])):
  b=date[i][-5:-1]
  year_corr.append(b)

for i in year_source:
  if i not in year_corr:
    print(i)

#According to result we can say that year value is the same with released date value

# try vice versa
for i in year_corr:
  if i not in year_source:
    print(i)

#According to result, we can say that there is a null in "released" column.

df[df["released"].isnull()]

#According to this result we should check released column

df[df["released"].isnull()]

#And i fill null values in released column with values in "year" column.
df.loc[[5728,5730],"released"]=df.loc[[5728,5730],"year"]

#We should somehow note and report that.

#To check values from max to min
df.sort_values(by=["gross"],inplace=False,ascending=False)

pd.set_option("display.max_rows",None)

#checking duplicates

#Version 1
df["company"].drop_duplicates().sort_values(ascending=False)

#Version 2
df["company"].value_counts()

df.drop_duplicates()

#Assume that there is a strong correlation between gross and budget so i try to prove my idea
sns.regplot(x="gross",y="budget",data=df)

sns.regplot(x="score",y="gross",data=df)

#To decide which correlation model i make some tests on data


from scipy.stats import shapiro

num_cols

for i in num_cols:
  statistic,p_value=shapiro(df[i])
  print(f"{i}:","Test statstic=%.4f,p_value=%.4f" % (statistic,p_value))

from scipy.stats import jarque_bera

for col in num_cols:
  statistic,result=jarque_bera(df[col])
  print(f"{col}:","Test statstic=%.4f,p_value=%.4f" % (statistic,p_value))

#According to results i choose KendallTau method

df[num_cols].corr(method="kendall")

correlation_matrix=df[num_cols].corr(method="kendall")

plt.title("Correlation matrix for Numeric Features")

plt.xlabel("Movie features")

plt.ylabel("Movie features")

sns.heatmap(correlation_matrix,annot=True)

correlation_matrix.unstack()

#According to this map, we can say that correlation rate between gross and votes and gross and budget is higher than other pari of values. But normally they can be classified as middle rated correlation level.
#Correlation between budget and gross is not strong as i claimed earlier.

#We try to create correlation for categoric_variables

df[cat_cols].nunique()

for i in df[cat_cols]:
  df[i]=df[i].astype("category")



correlation_matrix = df[cat_cols].apply(lambda x: x.factorize()[0]).corr(method='kendall')
sns.heatmap(correlation_matrix, annot = True)

plt.title("Correlation matrix for Movies")

plt.xlabel("Movie features")

plt.ylabel("Movie features")

plt.show()

df.columns

df["name"].head()

corr_pairs = correlation_matrix.unstack().sort_values(kind="quicksort")

print(corr_pairs.head())

# We can now take a look at the ones that have a high correlation (> 0.5)

strong_pairs = corr_pairs[abs(corr_pairs) > 0.5 ]

print(strong_pairs.head())

# Looking at the top 15 compaies by gross revenue

CompanyGrossSum = df.groupby('company')[["gross"]].sum()

CompanyGrossSumSorted = CompanyGrossSum.sort_values('gross', ascending = False)[:15]

CompanyGrossSumSorted = CompanyGrossSumSorted['gross'].astype('int64')

CompanyGrossSumSorted.head()

df.groupby(['company', 'year'])[["gross"]].sum()

plt.scatter(x=df['budget'], y=df['gross'], alpha=0.5)
plt.title('Budget vs Gross Earnings')
plt.xlabel('Gross Earnings')
plt.ylabel('Budget for Film')
plt.show()

df[cat_cols].head()

df.value_counts

df2=df.copy()

from sklearn.feature_extraction import FeatureHasher
h = FeatureHasher(n_features=10)
D = [{'dog': 1, 'cat':2, 'elephant':4},{'dog': 2, 'run': 5}]
f = h.transform(D)
f.toarray()

for col in cat_cols:
  df_hot=pd.get_dummies(df,columns=[col],prefix="_",dtype=int)

#Drop cardinal values for correlation
df_hot.drop(columns=cat_but_car,inplace=True)

df_hot.head()

df_hot.drop(columns=["rating","genre","country","company"],inplace=True)

correlation_matrix=df_hot.corr(method="kendall")
sns.heatmap(correlation_matrix, annot = True)

plt.title("Correlation matrix for Movies")

plt.xlabel("Movie features")

plt.ylabel("Movie features")

plt.show()

correlation_matrix

